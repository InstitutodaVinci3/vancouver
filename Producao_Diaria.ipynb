{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Producao_Diaria.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5b0jFO22sV5E"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InstitutodaVinci3/Vancouver/blob/master/Producao_Diaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0jFO22sV5E"
      },
      "source": [
        "#Resumo dos Trabalhos de Coleta, Limpeza e Entendimento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DasBz-Lu8Fo"
      },
      "source": [
        "##Biblotecas Utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj00MhVZfHpz"
      },
      "source": [
        "# importando as bibliotecas básicas e preparando ambiente\r\n",
        "import pandas as pd                     # convenção \r\n",
        "import numpy as np                      # convenção \r\n",
        "import random as rd                     # rd não é alias padrão mas sim adotado aqui somente \r\n",
        "# Itens adicionais\r\n",
        "import glob\r\n",
        "import os\r\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75O-RlH4r89u"
      },
      "source": [
        "##Coleta e Limpeza dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXNAaTZLzzpi"
      },
      "source": [
        "###Passo 1 - montagem do drive para colocação dos arquivos recebidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki_DsjtLKpCs",
        "outputId": "7c9c69db-e38e-407c-962a-90b46397ecc3"
      },
      "source": [
        "# montagem do Google Drive para acessar os arquivos que foram disponibilizados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLE_xgrZuN32"
      },
      "source": [
        "###Passo 2 - definição da varíavel \"Filenames\" para ser utilizado no \"for\" de leitura, de forma a correr todoos os arquivos do tipo TXT existentes no caminho (path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA9eXtg4fPtX"
      },
      "source": [
        "# Defifinindo a varíavel FIlenames para ser utilizado no \"for\" de leitura\r\n",
        "path =r'/content/drive/MyDrive/MedMep/Prod_Diaria/'\r\n",
        "filenames = glob.glob(path + \"/*.txt\")\r\n",
        "filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtfX6yidz_5V"
      },
      "source": [
        "###Passo 3 - Definição de como capturar a data que está no nome do arquivo\r\n",
        "#### É necessário capturar a data inserindo-a em uma coluna adicional para que possamos utilizar os dados de produção de leite em conjunto com os dados de temperatura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cPRmxePLxyY"
      },
      "source": [
        "# Ler parte do nome do arquivo\r\n",
        "b = re.search(r'(\\d+)', '/content/drive/MyDrive/MedMep/Prod_Diaria/Produção diária TXT_20170901T173500.txt')\r\n",
        "print(b[1])\r\n",
        "\r\n",
        "#Formatando Data\r\n",
        "import datetime\r\n",
        "datetime.datetime.strptime(\"20170901\", \"%Y%m%d\").strftime(\"%d/%m/%Y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__nCn9eI0Nv1"
      },
      "source": [
        "###Passo 4 - Leitura dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwCcqE627-lB"
      },
      "source": [
        "# Lendo os dados já com removendo o cabeçalho e rodapés dos arquivos\r\n",
        "# Necessário criar o \"Cabeçalho\" do DataFrame conforme comando asseguir:\r\n",
        "Prod_Dia_df = pd.DataFrame({'Grupo':[], 'Id_Animal':[], 'Num_Lac':[], 'Dias_Lac':[], 'Pico':[], 'Hora_S1':[],\r\n",
        "                            'Hora_S2':[], 'Hora_S3':[], 'Durac_S1':[], 'Durac_S2':[], 'Durac_S3':[],\r\n",
        "                            'Prod_S1':[], 'Prod_S2':[], 'Prod_S3':[], 'Hora_S1_ont':[], 'Hora_S2_ont':[], \r\n",
        "                            'Hora_S3_ont':[], 'Dura_S1_ont':[], 'Dura_S2_ont':[], \"Dura_S3_ont\":[],\r\n",
        "                            'Prod_S1_ont':[], 'Prod_S2_ont':[], 'Prod_S3_ont':[]})\r\n",
        "\r\n",
        "# Início do looping de leitura dos arquivos\r\n",
        "for filename in filenames:\r\n",
        "\r\n",
        "# Leitura dos arquivos já com o novo cabeçalho definido:\r\n",
        "  a = pd.read_csv(filename, skiprows=1, skipfooter=2, sep='\\t', encoding='latin1', engine='python', decimal=',',   \r\n",
        "                  names=['Grupo', 'Id_Animal', 'Num_Lac', 'Dias_Lac', 'Pico', 'Hora_S1', 'Hora_S2', 'Hora_S3',\r\n",
        "                         'Durac_S1', 'Durac_S2', 'Durac_S3', 'Prod_S1', 'Prod_S2', 'Prod_S3',\r\n",
        "                         'Hora_S1_ont', 'Hora_S2_ont', 'Hora_S3_ont', 'Dura_S1_ont', 'Dura_S2_ont', \"Dura_S3_ont\",\r\n",
        "                         'Prod_S1_ont', 'Prod_S2_ont', 'Prod_S3_ont'])\r\n",
        "\r\n",
        "# Criação da coluna adicional com a data contida no nome do arquivo:\r\n",
        "  a['Data']= datetime.datetime.strptime(re.search(r'(\\d+)', filename)[1], \"%Y%m%d\").strftime(\"%d/%m/%Y\") \r\n",
        "\r\n",
        "# Concatenando os arquivos lidos dentro do looping \r\n",
        "  Prod_Dia_df = pd.concat([Prod_Dia_df, a])\r\n",
        "# Fim do looping de leitura\r\n",
        "\r\n",
        "Prod_Dia_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbBaTKPu6a9t"
      },
      "source": [
        "- Foram disbonibilizados 177 arquivos no formato TXT\r\n",
        "- Foi necessário descartar a primeira linha (cabeçalho) de todos os arquivos por falta de padrão nos arquivos enviados\r\n",
        "- Foi necessário remover as duas últimas linhas que comtinham comnandos de \"end line\" e não seriam necessários ao ralizarmos a concatenação dos arquivos\r\n",
        "- Foi necessário criar uma nova definição para o cabeçalho do DataFrame\r\n",
        "- Foi necessário criar uma nova coluna para a inserção da data da coleta que estava no nome do arquivo\r\n",
        "- Os 177 arquivos foram lidos e concatenados gerando um único DataFrame unificado com todos os dados da Produção Diária de leite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGR7ok7zEte-"
      },
      "source": [
        "Prod_Dia_df.drop(columns=['Grupo', 'Num_Lac', 'Dias_Lac', 'Pico', 'Durac_S1', 'Durac_S2', 'Durac_S3', \r\n",
        "          'Hora_S1_ont', 'Hora_S2_ont', 'Hora_S3_ont', 'Dura_S1_ont', 'Dura_S2_ont', \"Dura_S3_ont\",\r\n",
        "          'Prod_S1_ont', 'Prod_S2_ont', 'Prod_S3_ont'], inplace=True)\r\n",
        "Prod_Dia_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NT6_eTNf3ko"
      },
      "source": [
        "# Extraindo as primeiras linhas do arquivo\r\n",
        "Prod_Dia_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J9CG_Paf8Yw"
      },
      "source": [
        "# Extraindo as últimas linhas do arquivo\r\n",
        "Prod_Dia_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jQGVUYBgAKT"
      },
      "source": [
        "# Prod_Dia_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5hjUZMmgZuQ"
      },
      "source": [
        "# Exportando dados dos arquivos unificados para Excel\r\n",
        "Prod_Dia_df.to_csv(\"/content/drive/MyDrive/MedMep/Prod_Diaria/Prod_Diaria_Unificado.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXt-r5l9smqW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VWME_FjiikW"
      },
      "source": [
        "##Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W4p5GltHinqX",
        "outputId": "6f4bdee9-5a11-4492-9bc0-d2ac47507102"
      },
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/InstitutodaVinci3/Vancouver/master/Prod_Diaria_Unificado.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id_Animal</th>\n",
              "      <th>Hora_S1</th>\n",
              "      <th>Hora_S2</th>\n",
              "      <th>Hora_S3</th>\n",
              "      <th>Prod_S1</th>\n",
              "      <th>Prod_S2</th>\n",
              "      <th>Prod_S3</th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>653.0</td>\n",
              "      <td>07:47</td>\n",
              "      <td>15:26</td>\n",
              "      <td></td>\n",
              "      <td>15.84</td>\n",
              "      <td>7.88</td>\n",
              "      <td></td>\n",
              "      <td>01/09/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2623.0</td>\n",
              "      <td>08:09</td>\n",
              "      <td>15:43</td>\n",
              "      <td></td>\n",
              "      <td>13.81</td>\n",
              "      <td>7.66</td>\n",
              "      <td></td>\n",
              "      <td>01/09/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2624.0</td>\n",
              "      <td>07:59</td>\n",
              "      <td>15:35</td>\n",
              "      <td></td>\n",
              "      <td>12.63</td>\n",
              "      <td>10.54</td>\n",
              "      <td></td>\n",
              "      <td>01/09/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2662.0</td>\n",
              "      <td>09:31</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>13.64</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>01/09/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3652.0</td>\n",
              "      <td>07:47</td>\n",
              "      <td>15:26</td>\n",
              "      <td></td>\n",
              "      <td>12.73</td>\n",
              "      <td>6.80</td>\n",
              "      <td></td>\n",
              "      <td>01/09/2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Id_Animal  ...                    Prod_S3        Data\n",
              "0           0      653.0  ...                             01/09/2017\n",
              "1           1     2623.0  ...                             01/09/2017\n",
              "2           2     2624.0  ...                             01/09/2017\n",
              "3           3     2662.0  ...                             01/09/2017\n",
              "4           4     3652.0  ...                             01/09/2017\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoh45xXbC-Pk"
      },
      "source": [
        "# Producao_S1 = Prod_Dia_df.groupby('Id_Animal').Prod_S1.sum()\r\n",
        "# Producao_S1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjbkCgRJEzRN"
      },
      "source": [
        "# Exportando dados dos arquivos unificados para Excel\r\n",
        "# Producao_S1.to_excel('/content/drive/MyDrive/MedMep/Prod_Diaria/Producao-S1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}